{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to the Amazon Fraud Detector API  \n",
    "#### Supervised fraud detection  \n",
    "-------\n",
    "- [Introduction](#Introduction)\n",
    "- [Setup](#Setup)\n",
    "- [Plan](#Plan)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "-------\n",
    "\n",
    "Amazon Fraud Detector is a fully managed service that makes it easy to identify potentially fraudulent online activities such as online payment fraud and the creation of fake accounts. Fraud Detector capitalizes on the latest advances in machine learning (ML) and 20 years of fraud detection expertise from AWS and Amazon.com to automatically identify potentially fraudulent activity so you can catch more fraud faster.\n",
    "\n",
    "In this notebook, we'll use the Amazon Fraud Detector API to define an entity and event of interest and use CSV data stored in S3 to train a model. Next, we'll derive some rules and create a \"detector\" by combining our entity, event, model, and rules into a single endpoint. Finally, we'll apply the detector to a sample of our data to identify potentially fraudulent events.\n",
    "\n",
    "After running this notebook you should be able to:\n",
    "- Define an Entity and Event\n",
    "- Create a Detector\n",
    "- Train a Machine Learning (ML) Model\n",
    "- Author Rules to identify potential fraud based on the model's score\n",
    "- Apply the Detector's \"predict\" function, to generate a model score and rule outcomes on data\n",
    "\n",
    "If you would like to know more, please check out [Fraud Detector's Documentation](https://docs.aws.amazon.com/frauddetector/). \n",
    "\n",
    "\n",
    "## Setup\n",
    "------\n",
    "First setup your AWS credentials so that Fraud Detector can store and access training data and supporting detector artifacts in S3.\n",
    "\n",
    "\n",
    "### Setting up AWS Credentials & Permissions\n",
    "\n",
    "https://docs.aws.amazon.com/frauddetector/latest/ug/set-up.html\n",
    "\n",
    "To use Amazon Fraud Detector, you have to set up permissions that allow access to the Amazon Fraud Detector console and API operations. You also have to allow Amazon Fraud Detector to perform tasks on your behalf and to access resources that you own. We recommend creating an AWS Identify and Access Management (IAM) user with access restricted to Amazon Fraud Detector operations and required permissions. You can add other permissions as needed.\n",
    "The following policies provide the required permission to use Amazon Fraud Detector:\n",
    "\n",
    "*AmazonFraudDetectorFullAccessPolicy* \n",
    "- Allows you to perform the following actions:\n",
    "    - Access all Amazon Fraud Detector resources  \n",
    "    - List and describe all model endpoints in Amazon SageMaker  \n",
    "    - List all IAM roles in the account  \n",
    "    - List all Amazon S3 buckets  \n",
    "    - Allow IAM Pass Role to pass a role to Amazon Fraud Detector  \n",
    "\n",
    "* AmazonS3FullAccess* \n",
    "- Allows full access to Amazon S3. This is required to upload training files to S3.\n",
    "\n",
    "  \n",
    "\n",
    "To use Amazon Fraud Detector, you have to set up permissions that allow access to the Amazon Fraud Detector console and API operations. You also have to allow Amazon Fraud Detector to perform tasks on your behalf and to access resources that you own. We recommend creating an AWS Identify and Access Management (IAM) user with access restricted to Amazon Fraud Detector operations and required permissions. You can add other permissions as needed.\n",
    "\n",
    "The following policies provide the required permission to use Amazon Fraud Detector:\n",
    "\n",
    "- *AmazonFraudDetectorFullAccessPolicy*  \n",
    "    Allows you to perform the following actions:  \n",
    "        - Access all Amazon Fraud Detector resources  \n",
    "        - List and describe all model endpoints in Amazon SageMaker  \n",
    "        - List all IAM roles in the account  \n",
    "        - List all Amazon S3 buckets  \n",
    "        - Allow IAM Pass Role to pass a role to Amazon Fraud Detector  \n",
    "\n",
    "- *AmazonS3FullAccess*  \n",
    "    Allows full access to Amazon S3. This is required to upload training files to S3.  \n",
    "\n",
    "\n",
    "\n",
    "## Plan\n",
    "### Plan a Fraud Detector\n",
    "------\n",
    "A Detector contains the event, model(s) and rule(s) detection logic for a particular type of fraud that you want to detect. We'll use the following 7 step process to plan a Fraud Detector:  \n",
    "\n",
    "1.\tSetup your notebook\n",
    "    - Name the major components entity, entity type, model, detector\n",
    "    - Plug in your ARN role\n",
    "    - Plug in your S3 Bucket and CSV File\n",
    "2.\tRead and Profile your Data\n",
    "    - This will give you an idea of what your dataset contains\n",
    "    - This will also identify the variables and labels that will need to be created to define your event\n",
    "3.\tCreate event variables and labels\n",
    "    - This will create the variables and labels in fraud detector\n",
    "4.\tDefine your Entity and Event Type\n",
    "    - What is the activity that you are detecting? That's likely your Event Type (e.g., account_registration)\n",
    "    - Who is performing this activity? That's likely your Entity (e.g., customer)\n",
    "5.\tCreate and Train your Model\n",
    "    - Model training takes anywhere from 45-60 minutes, once complete you need to promote your model\n",
    "    - Promote your model\n",
    "6.\tCreate Detector, generate Rules and assemble your Detector\n",
    "    - Create your detector\n",
    "    - Create rules based on your model scores\n",
    "        - Define outcomes (e.g., fraud, investigate and approve)\n",
    "    - Assemble your detector by adding your model and rules to it\n",
    "7.\tTest your Detector\n",
    "    - Interactively call predict on a handful of records\n",
    "\n",
    "\n",
    "A *Detector* contains the event, model(s) and rule(s) detection logic for a particular type of fraud that you want to detect. We'll use the following 7 step process to plan a Fraud Detector: \n",
    "\n",
    "1. Setup your notebook\n",
    "    - name the major components entity, entity type, model, detector .\n",
    "    - plug in your ARN role\n",
    "    - plug in your S3 Bucket and CSV File\n",
    "\n",
    "2. Read and Profile your Data. \n",
    "    - this will give you an idea of what your dataset contains. \n",
    "    - this will also identify the variables and labels that will need to be created to define your event. \n",
    " \n",
    "3. Create event variables and labels\n",
    "    - this will create the variables and labels in fraud detector \n",
    "    \n",
    "4. Define your Entity and Event Type \n",
    "    - What is activity that you are detecting? that's likely your Event Type ex. account_registration\n",
    "    - Who is performing this activity? that's likely your Entity ex. customer \n",
    "    \n",
    "5. Create and Train your Model   \n",
    "    - model training takes anywhere from 45-60 minutes, once complete you need to promote your endpoint  \n",
    "    - promote your model\n",
    "    \n",
    "6. Create Detector, generate Rules and assemble your Detector  \n",
    "    - create your detector \n",
    "    - create rules based on your model scores \n",
    "        - define outcomes ex:  fraud, investigate and approve \n",
    "    - assemble your detector \n",
    "        - combines rules and model into a \"detector\n",
    "    \n",
    "7. Test your Detector \n",
    "    - Interactively call predict on a handful of record \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import uuid \n",
    "from datetime import datetime\n",
    "\n",
    "# -- AWS stuff -- \n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# -- sklearn --\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, roc_auc_score\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- initialize the AFD client \n",
    "client = boto3.client('frauddetector')\n",
    "\n",
    "# -- suffix is appended to detector and model name for uniqueness  \n",
    "sufx   = datetime.now().strftime(\"%Y%m%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup \n",
    "-----\n",
    "\n",
    "***To get started ***  \n",
    "\n",
    "1. Name the major components of Fraud Detector.\n",
    "2. Plug in your ARN role \n",
    "3. Plug in your S3 Bucket and CSV File \n",
    "\n",
    "Then you can interactively exeucte the code cells in the notebook, no need to change anything unless you want to. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> <strong> Fraud Detector Components </strong>\n",
    "Fraud Detector Components:  EVENT_TYPE is a business activity that you want evaluated for fraud risk. ENTITY_TYPE represents the \"what or who\" that is performing the event you want to evaluate. MODEL_NAME is the name of your supervised machine learning model that Fraud Detector trains on your behalf. DETECTOR_NAME is the name of the detector that contains the detection logic (model and rules) that you apply to events that you want to evaluate for fraud.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "### Bucket, File, and ARN Role\n",
    "\n",
    "Bucket, ARN and Model Name Identify the following assets. S3_BUCKET is the name of the bucket where your file lives. S3_FILE is the URL to your s3 file. ARN_ROLE is the data access role \"ARN\" for the training data source.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><strong> Bucket, ARN and Model Name </strong>\n",
    "\n",
    "Identify the following assets. S3_BUCKET is the name of the bucket where your file lives. S3_FILE is the URL to your s3 file. ARN_ROLE is the data access role \"ARN\" for the training data source.\n",
    "\n",
    "</div>\n",
    "\n",
    "```\n",
    "Note: To use Amazon Fraud Detector, you have to set up permissions that allow access to the Amazon Fraud Detector console and API operations. You also have to allow Amazon Fraud Detector to perform tasks on your behalf and to access resources that you own. We recommend creating an AWS Identify and Access Management (IAM) user with access restricted to. Amazon Fraud Detector operations and required permissions. You can add other permissions as needed. See \"Create an IAM User and Assign Required Permissions\" in the user's guide:\n",
    "```\n",
    "https://docs.aws.amazon.com/frauddetector/latest/ug/frauddetector.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This is all you need to fill out. Once complete simply interactively run each code cell. --  \n",
    "\n",
    "ENTITY_TYPE    = \"customer{0}\".format(sufx) \n",
    "ENTITY_DESC    = \"entity description: {0}\".format(sufx) \n",
    "\n",
    "EVENT_TYPE     = \"cardpayment{0}\".format(sufx) \n",
    "EVENT_DESC     = \"example event description: {0}\".format(sufx) \n",
    "\n",
    "MODEL_NAME     = \"fraudmodel{0}\".format(sufx) \n",
    "MODEL_DESC     = \"model trained on: {0}\".format(sufx) \n",
    "\n",
    "DETECTOR_NAME  = \"detector{0}\".format(sufx)                        \n",
    "DETECTOR_DESC  = \"detects synthetic fraud events created: {0}\".format(sufx) \n",
    "\n",
    "ARN_ROLE       = \"arn:aws:iam::571660658801:role/service-role/AmazonFraudDetector-DataAccessRole-1601853778082\"\n",
    "S3_BUCKET      = \"bucketfraud\"\n",
    "S3_FILE        = \"train.csv\"\n",
    "S3_FILE_LOC    = \"s3://{0}/{1}\".format(S3_BUCKET,S3_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Data columns (total 82 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   r_y_d_e_r    590540 non-null  float64\n",
      " 1   j_l_q_m_p    590540 non-null  float64\n",
      " 2   v_o_g_p_t    590540 non-null  float64\n",
      " 3   a_x_w_d_r    590540 non-null  float64\n",
      " 4   j_k_p_g_w    590540 non-null  float64\n",
      " 5   f_u_y_f_q    590540 non-null  float64\n",
      " 6   p_x_x_d_o    590540 non-null  float64\n",
      " 7   e_z_h_o_k    590540 non-null  float64\n",
      " 8   m_q_m_p_h    590540 non-null  float64\n",
      " 9   u_x_p_x_p    590540 non-null  float64\n",
      " 10  n_g_i_d_g    590540 non-null  float64\n",
      " 11  o_r_e_q_p    590540 non-null  float64\n",
      " 12  z_l_u_c_r    590540 non-null  float64\n",
      " 13  w_p_l_z_k    590540 non-null  float64\n",
      " 14  o_p_o_f_n    590540 non-null  float64\n",
      " 15  w_v_t_p_w    590540 non-null  float64\n",
      " 16  a_m_z_w_x    590540 non-null  float64\n",
      " 17  t_x_d_q_g    590540 non-null  float64\n",
      " 18  o_j_e_v_b    590540 non-null  float64\n",
      " 19  b_n_v_z_o    590540 non-null  float64\n",
      " 20  h_l_d_m_a    590540 non-null  float64\n",
      " 21  r_v_b_b_i    590540 non-null  float64\n",
      " 22  l_k_q_x_w    590540 non-null  float64\n",
      " 23  p_x_a_f_u    590540 non-null  float64\n",
      " 24  y_w_o_n_z    590540 non-null  float64\n",
      " 25  r_a_j_g_w    590540 non-null  float64\n",
      " 26  h_t_v_r_a    590540 non-null  float64\n",
      " 27  m_t_h_d_u    590540 non-null  float64\n",
      " 28  l_r_n_t_p    590540 non-null  float64\n",
      " 29  d_m_s_y_h    590540 non-null  float64\n",
      " 30  d_w_n_n_p    590540 non-null  float64\n",
      " 31  c_o_g_d_g    590540 non-null  float64\n",
      " 32  g_y_r_w_f    590540 non-null  float64\n",
      " 33  u_k_z_h_u    590540 non-null  float64\n",
      " 34  q_v_z_i_u    590540 non-null  float64\n",
      " 35  l_c_r_a_b    590540 non-null  float64\n",
      " 36  o_o_u_j_l    590540 non-null  float64\n",
      " 37  k_s_e_p_a    590540 non-null  float64\n",
      " 38  x_c_e_u_m    590540 non-null  float64\n",
      " 39  i_c_f_u_f    590540 non-null  float64\n",
      " 40  q_t_o_x_g    590540 non-null  float64\n",
      " 41  i_y_z_o_r    590540 non-null  float64\n",
      " 42  n_f_a_q_j    590540 non-null  float64\n",
      " 43  y_c_h_t_y    590540 non-null  float64\n",
      " 44  j_l_x_u_c    590540 non-null  float64\n",
      " 45  g_c_i_t_a    590540 non-null  float64\n",
      " 46  t_b_s_p_i    590540 non-null  float64\n",
      " 47  s_p_p_r_q    590540 non-null  float64\n",
      " 48  x_g_g_x_x    590540 non-null  float64\n",
      " 49  c_b_j_v_u    590540 non-null  float64\n",
      " 50  k_j_s_h_f    590540 non-null  object \n",
      " 51  v_e_g_v_g    588963 non-null  object \n",
      " 52  c_v_n_m_e    588969 non-null  object \n",
      " 53  d_i_n_g_v    496084 non-null  object \n",
      " 54  m_z_w_y_t    137291 non-null  object \n",
      " 55  m_f_e_y_z    319440 non-null  object \n",
      " 56  g_f_l_j_m    319440 non-null  object \n",
      " 57  x_n_d_i_o    319440 non-null  object \n",
      " 58  v_z_h_g_g    309096 non-null  object \n",
      " 59  c_l_w_a_l    240058 non-null  object \n",
      " 60  v_r_o_s_j    421180 non-null  object \n",
      " 61  j_h_i_t_d    244275 non-null  object \n",
      " 62  l_g_x_o_s    244288 non-null  object \n",
      " 63  p_l_m_j_i    244288 non-null  object \n",
      " 64  w_y_j_j_o    144233 non-null  object \n",
      " 65  i_m_f_w_w    140985 non-null  object \n",
      " 66  u_t_l_a_h    129340 non-null  object \n",
      " 67  m_i_y_b_u    5169 non-null    object \n",
      " 68  d_z_m_a_a    5169 non-null    object \n",
      " 69  y_g_q_j_i    140978 non-null  object \n",
      " 70  z_x_w_p_n    140978 non-null  object \n",
      " 71  s_s_e_d_l    77565 non-null   object \n",
      " 72  p_l_i_p_p    140282 non-null  object \n",
      " 73  r_n_v_z_y    73289 non-null   object \n",
      " 74  v_y_d_l_g    77805 non-null   object \n",
      " 75  r_e_x_l_p    140985 non-null  object \n",
      " 76  z_j_a_i_y    140985 non-null  object \n",
      " 77  l_b_b_l_o    140985 non-null  object \n",
      " 78  w_w_o_c_t    140985 non-null  object \n",
      " 79  d_m_q_o_y    140810 non-null  object \n",
      " 80  h_c_f_e_n    118666 non-null  object \n",
      " 81  EVENT_LABEL  590540 non-null  int64  \n",
      "dtypes: float64(50), int64(1), object(31)\n",
      "memory usage: 369.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(S3_FILE_LOC )\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Profile Your Dataset \n",
    "-----\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Profiling </strong>\n",
    "\n",
    "The function below will: 1. profile your data, creating descriptive statistics, 2. perform basic data quality checks (nulls, unique variables, etc.), and 3. return summary statistics and the EVENT and MODEL schemas used to define your EVENT_TYPE and TRAIN your MODEL.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- summary stats ---\n",
      "   feature_name    dtype   count  nunique    null  not_null  null_pct  nunique_pct feature_type               feature_warning\n",
      "0     r_y_d_e_r  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "1     j_l_q_m_p  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "2     v_o_g_p_t  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "3     a_x_w_d_r  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "4     j_k_p_g_w  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "5     f_u_y_f_q  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "6     p_x_x_d_o  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "7     e_z_h_o_k  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "8     m_q_m_p_h  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "9     u_x_p_x_p  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "10    n_g_i_d_g  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "11    o_r_e_q_p  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "12    z_l_u_c_r  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "13    w_p_l_z_k  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "14    o_p_o_f_n  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "15    w_v_t_p_w  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "16    a_m_z_w_x  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "17    t_x_d_q_g  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "18    o_j_e_v_b  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "19    b_n_v_z_o  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "20    h_l_d_m_a  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "21    r_v_b_b_i  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "22    l_k_q_x_w  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "23    p_x_a_f_u  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "24    y_w_o_n_z  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "25    r_a_j_g_w  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "26    h_t_v_r_a  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "27    m_t_h_d_u  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "28    l_r_n_t_p  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "29    d_m_s_y_h  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "30    d_w_n_n_p  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "31    c_o_g_d_g  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "32    g_y_r_w_f  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "33    u_k_z_h_u  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "34    q_v_z_i_u  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "35    l_c_r_a_b  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "36    o_o_u_j_l  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "37    k_s_e_p_a  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "38    x_c_e_u_m  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "39    i_c_f_u_f  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "40    q_t_o_x_g  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "41    i_y_z_o_r  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "42    n_f_a_q_j  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "43    y_c_h_t_y  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "44    j_l_x_u_c  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "45    g_c_i_t_a  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "46    t_b_s_p_i  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "47    s_p_p_r_q  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "48    x_g_g_x_x  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "49    c_b_j_v_u  float64  590540   590540       0    590540    0.0000       1.0000      NUMERIC                    NO WARNING\n",
      "50    k_j_s_h_f   object  590540        5       0    590540    0.0000       0.0000     CATEGORY                    NO WARNING\n",
      "51    v_e_g_v_g   object  588963        4    1577    588963    0.0027       0.0000     CATEGORY                    NO WARNING\n",
      "52    c_v_n_m_e   object  588969        4    1571    588969    0.0027       0.0000     CATEGORY                    NO WARNING\n",
      "53    d_i_n_g_v   object  496084       59   94456    496084    0.1599       0.0001     CATEGORY                    NO WARNING\n",
      "54    m_z_w_y_t   object  137291       60  453249    137291    0.7675       0.0001     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "55    m_f_e_y_z   object  319440        2  271100    319440    0.4591       0.0000     CATEGORY  NULL WARNING, GT 20% MISSING\n",
      "56    g_f_l_j_m   object  319440        2  271100    319440    0.4591       0.0000     CATEGORY  NULL WARNING, GT 20% MISSING\n",
      "57    x_n_d_i_o   object  319440        2  271100    319440    0.4591       0.0000     CATEGORY  NULL WARNING, GT 20% MISSING\n",
      "58    v_z_h_g_g   object  309096        3  281444    309096    0.4766       0.0000     CATEGORY  NULL WARNING, GT 20% MISSING\n",
      "59    c_l_w_a_l   object  240058        2  350482    240058    0.5935       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "60    v_r_o_s_j   object  421180        2  169360    421180    0.2868       0.0000     CATEGORY  NULL WARNING, GT 20% MISSING\n",
      "61    j_h_i_t_d   object  244275        2  346265    244275    0.5864       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "62    l_g_x_o_s   object  244288        2  346252    244288    0.5863       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "63    p_l_m_j_i   object  244288        2  346252    244288    0.5863       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "64    w_y_j_j_o   object  144233        2  446307    144233    0.7558       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "65    i_m_f_w_w   object  140985        3  449555    140985    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "66    u_t_l_a_h   object  129340        2  461200    129340    0.7810       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "67    m_i_y_b_u   object    5169        3  585371      5169    0.9912       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "68    d_z_m_a_a   object    5169        2  585371      5169    0.9912       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "69    y_g_q_j_i   object  140978        2  449562    140978    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "70    z_x_w_p_n   object  140978        2  449562    140978    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "71    s_s_e_d_l   object   77565       75  512975     77565    0.8687       0.0001     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "72    p_l_i_p_p   object  140282      130  450258    140282    0.7625       0.0002     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "73    r_n_v_z_y   object   73289      260  517251     73289    0.8759       0.0004     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "74    v_y_d_l_g   object   77805        4  512735     77805    0.8682       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "75    r_e_x_l_p   object  140985        2  449555    140985    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "76    z_j_a_i_y   object  140985        2  449555    140985    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "77    l_b_b_l_o   object  140985        2  449555    140985    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "78    w_w_o_c_t   object  140985        2  449555    140985    0.7613       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "79    d_m_q_o_y   object  140810        2  449730    140810    0.7616       0.0000     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "80    h_c_f_e_n   object  118666     1786  471874    118666    0.7991       0.0030     CATEGORY       EXCLUDE, GT 50% MISSING\n",
      "81  EVENT_LABEL   object  590540        2       0    590540    0.0000       0.0000       TARGET                    NO WARNING\n",
      "\n",
      "\n",
      "--- event variables ---\n",
      "['r_y_d_e_r', 'j_l_q_m_p', 'v_o_g_p_t', 'a_x_w_d_r', 'j_k_p_g_w', 'f_u_y_f_q', 'p_x_x_d_o', 'e_z_h_o_k', 'm_q_m_p_h', 'u_x_p_x_p', 'n_g_i_d_g', 'o_r_e_q_p', 'z_l_u_c_r', 'w_p_l_z_k', 'o_p_o_f_n', 'w_v_t_p_w', 'a_m_z_w_x', 't_x_d_q_g', 'o_j_e_v_b', 'b_n_v_z_o', 'h_l_d_m_a', 'r_v_b_b_i', 'l_k_q_x_w', 'p_x_a_f_u', 'y_w_o_n_z', 'r_a_j_g_w', 'h_t_v_r_a', 'm_t_h_d_u', 'l_r_n_t_p', 'd_m_s_y_h', 'd_w_n_n_p', 'c_o_g_d_g', 'g_y_r_w_f', 'u_k_z_h_u', 'q_v_z_i_u', 'l_c_r_a_b', 'o_o_u_j_l', 'k_s_e_p_a', 'x_c_e_u_m', 'i_c_f_u_f', 'q_t_o_x_g', 'i_y_z_o_r', 'n_f_a_q_j', 'y_c_h_t_y', 'j_l_x_u_c', 'g_c_i_t_a', 't_b_s_p_i', 's_p_p_r_q', 'x_g_g_x_x', 'c_b_j_v_u', 'k_j_s_h_f', 'v_e_g_v_g', 'c_v_n_m_e', 'd_i_n_g_v', 'm_z_w_y_t', 'm_f_e_y_z', 'g_f_l_j_m', 'x_n_d_i_o', 'v_z_h_g_g', 'c_l_w_a_l', 'v_r_o_s_j', 'j_h_i_t_d', 'l_g_x_o_s', 'p_l_m_j_i', 'w_y_j_j_o', 'i_m_f_w_w', 'u_t_l_a_h', 'm_i_y_b_u', 'd_z_m_a_a', 'y_g_q_j_i', 'z_x_w_p_n', 's_s_e_d_l', 'p_l_i_p_p', 'r_n_v_z_y', 'v_y_d_l_g', 'r_e_x_l_p', 'z_j_a_i_y', 'l_b_b_l_o', 'w_w_o_c_t', 'd_m_q_o_y', 'h_c_f_e_n']\n",
      "\n",
      "\n",
      "--- event labels ---\n",
      "['0', '1']\n",
      "\n",
      "\n",
      "--- training data schema ---\n",
      "{'modelVariables': ['r_y_d_e_r', 'j_l_q_m_p', 'v_o_g_p_t', 'a_x_w_d_r', 'j_k_p_g_w', 'f_u_y_f_q', 'p_x_x_d_o', 'e_z_h_o_k', 'm_q_m_p_h', 'u_x_p_x_p', 'n_g_i_d_g', 'o_r_e_q_p', 'z_l_u_c_r', 'w_p_l_z_k', 'o_p_o_f_n', 'w_v_t_p_w', 'a_m_z_w_x', 't_x_d_q_g', 'o_j_e_v_b', 'b_n_v_z_o', 'h_l_d_m_a', 'r_v_b_b_i', 'l_k_q_x_w', 'p_x_a_f_u', 'y_w_o_n_z', 'r_a_j_g_w', 'h_t_v_r_a', 'm_t_h_d_u', 'l_r_n_t_p', 'd_m_s_y_h', 'd_w_n_n_p', 'c_o_g_d_g', 'g_y_r_w_f', 'u_k_z_h_u', 'q_v_z_i_u', 'l_c_r_a_b', 'o_o_u_j_l', 'k_s_e_p_a', 'x_c_e_u_m', 'i_c_f_u_f', 'q_t_o_x_g', 'i_y_z_o_r', 'n_f_a_q_j', 'y_c_h_t_y', 'j_l_x_u_c', 'g_c_i_t_a', 't_b_s_p_i', 's_p_p_r_q', 'x_g_g_x_x', 'c_b_j_v_u', 'k_j_s_h_f', 'v_e_g_v_g', 'c_v_n_m_e', 'd_i_n_g_v', 'm_z_w_y_t', 'm_f_e_y_z', 'g_f_l_j_m', 'x_n_d_i_o', 'v_z_h_g_g', 'c_l_w_a_l', 'v_r_o_s_j', 'j_h_i_t_d', 'l_g_x_o_s', 'p_l_m_j_i', 'w_y_j_j_o', 'i_m_f_w_w', 'u_t_l_a_h', 'm_i_y_b_u', 'd_z_m_a_a', 'y_g_q_j_i', 'z_x_w_p_n', 's_s_e_d_l', 'p_l_i_p_p', 'r_n_v_z_y', 'v_y_d_l_g', 'r_e_x_l_p', 'z_j_a_i_y', 'l_b_b_l_o', 'w_w_o_c_t', 'd_m_q_o_y', 'h_c_f_e_n'], 'labelSchema': {'labelMapper': {'FRAUD': ['1'], 'LEGIT': ['0']}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- no changes; just run this code block ---\n",
    "def summary_stats(df):\n",
    "    \"\"\" Generate summary statistics for a panda's data frame \n",
    "        Args:\n",
    "            df (DataFrame): panda's dataframe to create summary statistics for.\n",
    "        Returns:\n",
    "            DataFrame of summary statistics, training data schema, event variables and event lables \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    rowcnt = len(df)\n",
    "    df['EVENT_LABEL'] = df['EVENT_LABEL'].astype('str', errors='ignore')\n",
    "    df_s1  = df.agg(['count', 'nunique']).transpose().reset_index().rename(columns={\"index\":\"feature_name\"})\n",
    "    df_s1[\"null\"] = (rowcnt - df_s1[\"count\"]).astype('int64')\n",
    "    df_s1[\"not_null\"] = rowcnt - df_s1[\"null\"]\n",
    "    df_s1[\"null_pct\"] = df_s1[\"null\"] / rowcnt\n",
    "    df_s1[\"nunique_pct\"] = df_s1['nunique']/ rowcnt\n",
    "    dt = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\":\"feature_name\", 0:\"dtype\"})\n",
    "    df_stats = pd.merge(dt, df_s1, on='feature_name', how='inner').round(4)\n",
    "    df_stats['nunique'] = df_stats['nunique'].astype('int64')\n",
    "    df_stats['count'] = df_stats['count'].astype('int64')\n",
    "    \n",
    "    # -- variable type mapper --  \n",
    "    df_stats['feature_type'] = \"UNKOWN\"\n",
    "    df_stats.loc[df_stats[\"dtype\"] == object, 'feature_type'] = \"CATEGORY\"\n",
    "    df_stats.loc[(df_stats[\"dtype\"] == \"int64\") | (df_stats[\"dtype\"] == \"float64\"), 'feature_type'] = \"NUMERIC\"\n",
    "    df_stats.loc[df_stats[\"feature_name\"].str.contains(\"ipaddress|ip_address|ipaddr\"), 'feature_type'] = \"IP_ADDRESS\"\n",
    "    df_stats.loc[df_stats[\"feature_name\"].str.contains(\"email|email_address|emailaddr\"), 'feature_type'] = \"EMAIL_ADDRESS\"\n",
    "    df_stats.loc[df_stats[\"feature_name\"] == \"EVENT_LABEL\", 'feature_type'] = \"TARGET\"\n",
    "    df_stats.loc[df_stats[\"feature_name\"] == \"EVENT_TIMESTAMP\", 'feature_type'] = \"EVENT_TIMESTAMP\"\n",
    "    \n",
    "    # -- variable warnings -- \n",
    "    df_stats['feature_warning'] = \"NO WARNING\"\n",
    "    df_stats.loc[(df_stats[\"nunique\"] != 2) & (df_stats[\"feature_name\"] == \"EVENT_LABEL\"),'feature_warning' ] = \"LABEL WARNING, NON-BINARY EVENT LABEL\"\n",
    "    df_stats.loc[(df_stats[\"nunique_pct\"] > 0.9) & (df_stats['feature_type'] == \"CATEGORY\") ,'feature_warning' ] = \"EXCLUDE, GT 90% UNIQUE\"\n",
    "    df_stats.loc[(df_stats[\"null_pct\"] > 0.2) & (df_stats[\"null_pct\"] <= 0.5), 'feature_warning' ] = \"NULL WARNING, GT 20% MISSING\"\n",
    "    df_stats.loc[df_stats[\"null_pct\"] > 0.5,'feature_warning' ] = \"EXCLUDE, GT 50% MISSING\"\n",
    "    df_stats.loc[((df_stats['dtype'] == \"int64\" ) | (df_stats['dtype'] == \"float64\" ) ) & (df_stats['nunique'] < 0.2), 'feature_warning' ] = \"LIKELY CATEGORICAL, NUMERIC w. LOW CARDINALITY\"\n",
    "   \n",
    "    # -- target check -- \n",
    "    exclude_fields  = df_stats.loc[(df_stats['feature_warning'] != 'NO WARNING')]['feature_name'].to_list()\n",
    "    event_variables = df_stats.loc[(~df_stats['feature_name'].isin(['EVENT_LABEL', 'EVENT_TIMESTAMP']))]['feature_name'].to_list()\n",
    "    event_labels    = df[\"EVENT_LABEL\"].unique().tolist()\n",
    "    \n",
    "    trainingDataSchema = {\n",
    "        'modelVariables' : df_stats.loc[(df_stats['feature_type'].isin(['IP_ADDRESS', 'EMAIL_ADDRESS', 'CATEGORY', 'NUMERIC' ]))]['feature_name'].to_list(),\n",
    "        'labelSchema'    : {\n",
    "            'labelMapper' : {\n",
    "                'FRAUD' : [df[\"EVENT_LABEL\"].value_counts().idxmin()],\n",
    "                'LEGIT' : [df[\"EVENT_LABEL\"].value_counts().idxmax()]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    model_variables = df_stats.loc[(df_stats['feature_type'].isin(['IP_ADDRESS', 'EMAIL_ADDRESS', 'CATEGORY', 'NUMERIC' ]))]['feature_name'].to_list()\n",
    "   \n",
    "    \n",
    "    # -- label schema -- \n",
    "    label_map = {\n",
    "        'FRAUD' : [df[\"EVENT_LABEL\"].value_counts().idxmin()],\n",
    "        'LEGIT' : [df[\"EVENT_LABEL\"].value_counts().idxmax()]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    print(\"--- summary stats ---\")\n",
    "    print(df_stats)\n",
    "    print(\"\\n\")\n",
    "    print(\"--- event variables ---\")\n",
    "    print(event_variables)\n",
    "    print(\"\\n\")\n",
    "    print(\"--- event labels ---\")\n",
    "    print(event_labels)\n",
    "    print(\"\\n\")\n",
    "    print(\"--- training data schema ---\")\n",
    "    print(trainingDataSchema)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return df_stats, trainingDataSchema, event_variables, event_labels\n",
    "\n",
    "# -- connect to S3, snag file, and convert to a panda's dataframe --\n",
    "s3   = boto3.resource('s3')\n",
    "obj  = s3.Object(S3_BUCKET, S3_FILE)\n",
    "body = obj.get()['Body']\n",
    "df   = pd.read_csv(body)\n",
    "\n",
    "# -- call profiling function -- \n",
    "df_stats, trainingDataSchema, eventVariables, eventLabels = summary_stats(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Variables\n",
    "-----\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Create Variables. </strong>\n",
    "\n",
    "The following section will automatically create your modeling input variables and your model scoring variable for you. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.loc[(df_stats['feature_type'].isin(['IP_ADDRESS', 'EMAIL_ADDRESS']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variable: fraudmodel20201209insightscore\n",
      "\n",
      " --- model variable dict --\n",
      "[{'name': 'r_y_d_e_r'}, {'name': 'j_l_q_m_p'}, {'name': 'v_o_g_p_t'}, {'name': 'a_x_w_d_r'}, {'name': 'j_k_p_g_w'}, {'name': 'f_u_y_f_q'}, {'name': 'p_x_x_d_o'}, {'name': 'e_z_h_o_k'}, {'name': 'm_q_m_p_h'}, {'name': 'u_x_p_x_p'}, {'name': 'n_g_i_d_g'}, {'name': 'o_r_e_q_p'}, {'name': 'z_l_u_c_r'}, {'name': 'w_p_l_z_k'}, {'name': 'o_p_o_f_n'}, {'name': 'w_v_t_p_w'}, {'name': 'a_m_z_w_x'}, {'name': 't_x_d_q_g'}, {'name': 'o_j_e_v_b'}, {'name': 'b_n_v_z_o'}, {'name': 'h_l_d_m_a'}, {'name': 'r_v_b_b_i'}, {'name': 'l_k_q_x_w'}, {'name': 'p_x_a_f_u'}, {'name': 'y_w_o_n_z'}, {'name': 'r_a_j_g_w'}, {'name': 'h_t_v_r_a'}, {'name': 'm_t_h_d_u'}, {'name': 'l_r_n_t_p'}, {'name': 'd_m_s_y_h'}, {'name': 'd_w_n_n_p'}, {'name': 'c_o_g_d_g'}, {'name': 'g_y_r_w_f'}, {'name': 'u_k_z_h_u'}, {'name': 'q_v_z_i_u'}, {'name': 'l_c_r_a_b'}, {'name': 'o_o_u_j_l'}, {'name': 'k_s_e_p_a'}, {'name': 'x_c_e_u_m'}, {'name': 'i_c_f_u_f'}, {'name': 'q_t_o_x_g'}, {'name': 'i_y_z_o_r'}, {'name': 'n_f_a_q_j'}, {'name': 'y_c_h_t_y'}, {'name': 'j_l_x_u_c'}, {'name': 'g_c_i_t_a'}, {'name': 't_b_s_p_i'}, {'name': 's_p_p_r_q'}, {'name': 'x_g_g_x_x'}, {'name': 'c_b_j_v_u'}, {'name': 'k_j_s_h_f'}, {'name': 'v_e_g_v_g'}, {'name': 'c_v_n_m_e'}, {'name': 'd_i_n_g_v'}, {'name': 'm_z_w_y_t'}, {'name': 'm_f_e_y_z'}, {'name': 'g_f_l_j_m'}, {'name': 'x_n_d_i_o'}, {'name': 'v_z_h_g_g'}, {'name': 'c_l_w_a_l'}, {'name': 'v_r_o_s_j'}, {'name': 'j_h_i_t_d'}, {'name': 'l_g_x_o_s'}, {'name': 'p_l_m_j_i'}, {'name': 'w_y_j_j_o'}, {'name': 'i_m_f_w_w'}, {'name': 'u_t_l_a_h'}, {'name': 'm_i_y_b_u'}, {'name': 'd_z_m_a_a'}, {'name': 'y_g_q_j_i'}, {'name': 'z_x_w_p_n'}, {'name': 's_s_e_d_l'}, {'name': 'p_l_i_p_p'}, {'name': 'r_n_v_z_y'}, {'name': 'v_y_d_l_g'}, {'name': 'r_e_x_l_p'}, {'name': 'z_j_a_i_y'}, {'name': 'l_b_b_l_o'}, {'name': 'w_w_o_c_t'}, {'name': 'd_m_q_o_y'}, {'name': 'h_c_f_e_n'}]\n",
      "\n",
      " --- model label schema dict --\n",
      "{'labelKey': 'EVENT_LABEL', 'labelMapper': {'FRAUD': ['1'], 'LEGIT': ['0']}}\n"
     ]
    }
   ],
   "source": [
    "# --- no changes just run this code block ---\n",
    "def create_label(df, FRAUD_LABEL):\n",
    "    \"\"\"\n",
    "    Returns a dictionary for the model labelSchema, by identifying the rare event as fraud / and common as not-fraud \n",
    "    \n",
    "    Arguments:\n",
    "    df          -- input dataframe \n",
    "    FRAUD_LABEL -- the name of the field that contains fraud label  \n",
    "    \n",
    "    Returns:\n",
    "    labelSchema -- a dictionary containing labelKey & labelMapper \n",
    "    \"\"\"\n",
    "    label_summary = df[FRAUD_LABEL].value_counts()\n",
    "    labelSchema = {'labelKey': FRAUD_LABEL,\n",
    "                   \"labelMapper\" : { \"FRAUD\": [str(label_summary.idxmin())], \n",
    "                                     \"LEGIT\": [str(label_summary.idxmax())]}\n",
    "                  }\n",
    "    client.put_label(\n",
    "                name = str(label_summary.idxmin()),\n",
    "                description = 'FRAUD')\n",
    "    \n",
    "    client.put_label(\n",
    "                name = str(label_summary.idxmax()),\n",
    "                description = 'LEGIT')\n",
    "    return labelSchema\n",
    "    \n",
    "# -- function to create all your variables --- \n",
    "def create_variables(df_stats, MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Returns a variable list of model input variables, checks to see if variable exists,\n",
    "    and, if not, then it adds the variable to Fraud Detector \n",
    "    \n",
    "    Arguments: \n",
    "    enrichment_features  -- dictionary of optional features, mapped to specific variable types enriched (CARD_BIN, USERAGENT)\n",
    "    numeric_features     -- optional list of numeric field names \n",
    "    categorical_features -- optional list of categorical features \n",
    "    \n",
    "    Returns:\n",
    "    variable_list -- a list of variable dictionaries \n",
    "    \n",
    "    \"\"\"\n",
    "    enrichment_features = df_stats.loc[(df_stats['feature_type'].isin(['IP_ADDRESS', 'EMAIL_ADDRESS']))].to_dict(orient=\"record\")\n",
    "    numeric_features = df_stats.loc[(df_stats['feature_type'].isin(['NUMERIC']))]['feature_name'].to_dict()\n",
    "    categorical_features = df_stats.loc[(df_stats['feature_type'].isin(['CATEGORY']))]['feature_name'].to_dict()\n",
    "    \n",
    "    variable_list = []\n",
    "    # -- first do the enrichment features\n",
    "    for feature in enrichment_features: \n",
    "        variable_list.append( {'name' : feature['feature_name']})\n",
    "        try:\n",
    "            resp = client.get_variables(name=feature['feature_name'])\n",
    "        except:\n",
    "            print(\"Creating variable: {0}\".format(feature['feature_name']))\n",
    "            resp = client.create_variable(\n",
    "                    name = feature['feature_name'],\n",
    "                    dataType = 'STRING',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '<unknown>', \n",
    "                    description = feature['feature_name'],\n",
    "                    variableType = feature['feature_type'] )\n",
    "                \n",
    "               \n",
    "    # -- check and update the numeric features \n",
    "    for feature in numeric_features: \n",
    "        variable_list.append( {'name' : numeric_features[feature]})\n",
    "        try:\n",
    "            resp = client.get_variables(name=numeric_features[feature])\n",
    "        except:\n",
    "            print(\"Creating variable: {0}\".format(numeric_features[feature]))\n",
    "            resp = client.create_variable(\n",
    "                    name = numeric_features[feature],\n",
    "                    dataType = 'FLOAT',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '0.0', \n",
    "                    description = numeric_features[feature],\n",
    "                    variableType = 'NUMERIC' )\n",
    "             \n",
    "    # -- check and update the categorical features \n",
    "    for feature in categorical_features: \n",
    "        variable_list.append( {'name' : categorical_features[feature]})\n",
    "        try:\n",
    "            resp = client.get_variables(name=categorical_features[feature])\n",
    "        except:\n",
    "            print(\"Creating variable: {0}\".format(categorical_features[feature]))\n",
    "            resp = client.create_variable(\n",
    "                    name = categorical_features[feature],\n",
    "                    dataType = 'STRING',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '<unknown>', \n",
    "                    description = categorical_features[feature],\n",
    "                    variableType = 'CATEGORICAL' )\n",
    "    \n",
    "    # -- create a model score feature  \n",
    "    model_feature = \"{0}insightscore\".format(MODEL_NAME)  \n",
    "    # variable_list.append( {'name' : model_feature})\n",
    "    try:\n",
    "        resp = client.get_variables(name=model_feature)\n",
    "    except:\n",
    "        print(\"Creating variable: {0}\".format(model_feature))\n",
    "        resp = client.create_variable(\n",
    "                name = model_feature,\n",
    "                dataType = 'FLOAT',\n",
    "                dataSource ='EXTERNAL_MODEL_SCORE',\n",
    "                defaultValue = '0.0', \n",
    "                description = model_feature,\n",
    "                variableType = 'NUMERIC' )\n",
    "    \n",
    "    return variable_list\n",
    "\n",
    "\n",
    "model_variables = create_variables(df_stats, MODEL_NAME)\n",
    "print(\"\\n --- model variable dict --\")\n",
    "print(model_variables)\n",
    "\n",
    "\n",
    "model_label = create_label(df, \"EVENT_LABEL\")\n",
    "print(\"\\n --- model label schema dict --\")\n",
    "print(model_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Entity and Event Types\n",
    "-----\n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Entity and Event. </strong>\n",
    "    \n",
    "The following code block will automatically create your entity and event types for you.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConflictException",
     "evalue": "An error occurred (ConflictException) when calling the DeleteVariable operation: One or more EventType are using 'a_m_z_w_x'. Remove this variable from EventType or remove the EventType first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConflictException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e5faf6d84aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConflictException\u001b[0m: An error occurred (ConflictException) when calling the DeleteVariable operation: One or more EventType are using 'a_m_z_w_x'. Remove this variable from EventType or remove the EventType first."
     ]
    }
   ],
   "source": [
    "a=[\"a_d_d_d_a\",\n",
    "\"a_f_n_k_y\",\n",
    "\"a_g_i_d_h\",\n",
    "\"a_m_z_w_x\",\n",
    "\"a_r_m_e_u\",\n",
    "\"a_x_w_d_r\",\n",
    "\"addr1\",\n",
    "\"addr2\",\n",
    "\"b_d_r_z_x\",\n",
    "\"b_h_i_q_k\",\n",
    "\"b_j_w_p_s\",\n",
    "\"b_n_v_z_o\",\n",
    "\"b_o_o_p_p\",\n",
    "\"b_p_k_u_d\",\n",
    "\"b_s_r_e_w\",\n",
    "\"b_v_a_i_f\",\n",
    "\"b_v_i_j_e\",\n",
    "\"b_x_g_u_k\",\n",
    "\"billing_address\",\n",
    "\"billing_postal\",\n",
    "\"billing_state\",\n",
    "\"c1\",\n",
    "\"c10\",\n",
    "\"c11\",\n",
    "\"c12\",\n",
    "\"c13\",\n",
    "\"c14\",\n",
    "\"c2\",\n",
    "\"c3\",\n",
    "\"c4\",\n",
    "\"c5\",\n",
    "\"c6\",\n",
    "\"c7\",\n",
    "\"c8\",\n",
    "\"c9\",\n",
    "\"c_b_j_v_u\",\n",
    "\"c_f_a_k_y\",\n",
    "\"c_j_w_y_e\",\n",
    "\"c_k_x_b_l\",\n",
    "\"c_l_w_a_l\",\n",
    "\"c_o_g_d_g\",\n",
    "\"c_r_l_x_t\",\n",
    "\"c_v_n_m_e\",\n",
    "\"c_z_g_l_p\",\n",
    "\"c_z_o_l_e\",\n",
    "\"card1\",\n",
    "\"card2\",\n",
    "\"card3\",\n",
    "\"card4\",\n",
    "\"card5\",\n",
    "\"card6\",\n",
    "\"d1\",\n",
    "\"d10\",\n",
    "\"d11\",\n",
    "\"d12\",\n",
    "\"d13\",\n",
    "\"d14\",\n",
    "\"d15\",\n",
    "\"d2\",\n",
    "\"d3\",\n",
    "\"d4\",\n",
    "\"d5\",\n",
    "\"d6\",\n",
    "\"d7\",\n",
    "\"d8\",\n",
    "\"d9\",\n",
    "\"d_c_p_o_b\",\n",
    "\"d_d_a_m_n\",\n",
    "\"d_f_u_q_g\",\n",
    "\"d_i_n_g_v\",\n",
    "\"d_l_h_k_m\",\n",
    "\"d_m_q_o_y\",\n",
    "\"d_m_s_y_h\",\n",
    "\"d_r_d_u_b\",\n",
    "\"d_v_v_m_z\",\n",
    "\"d_w_n_n_p\",\n",
    "\"d_w_q_y_e\",\n",
    "\"d_z_m_a_a\",\n",
    "\"deviceinfo\",\n",
    "\"devicetype\",\n",
    "\"dist1\",\n",
    "\"dist2\",\n",
    "\"e_d_q_g_c\",\n",
    "\"e_f_a_v_h\",\n",
    "\"e_k_c_n_w\",\n",
    "\"e_k_l_r_h\",\n",
    "\"e_t_s_j_p\",\n",
    "\"e_v_p_e_m\",\n",
    "\"e_z_h_o_k\",\n",
    "\"email_address\",\n",
    "\"f_a_m_f_r\",\n",
    "\"f_a_q_l_v\",\n",
    "\"f_e_r_z_z\",\n",
    "\"f_q_k_y_g\",\n",
    "\"f_q_x_x_o\",\n",
    "\"f_s_r_i_b\",\n",
    "\"f_u_y_f_q\",\n",
    "\"fraudmodel20201209_insightscore\",\n",
    "\"fraudmodel20201209insightscore\",\n",
    "\"g_a_z_u_a\"\n",
    "]\n",
    "\n",
    "for i in a:\n",
    "    client.delete_variable(name=i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- create entity --\n",
      "{'ResponseMetadata': {'RequestId': 'f63433f5-8d8b-4930-bae8-c9af48f4d298', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Dec 2020 02:34:14 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': 'f63433f5-8d8b-4930-bae8-c9af48f4d298'}, 'RetryAttempts': 0}}\n",
      "-- create event type --\n",
      "{'ResponseMetadata': {'RequestId': '20915cd8-f225-4009-805d-2a3ea967d402', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Dec 2020 02:34:14 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': '20915cd8-f225-4009-805d-2a3ea967d402'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# --- no changes just run this code block ---\n",
    "response = client.put_entity_type(\n",
    "    name        = ENTITY_TYPE,\n",
    "    description = ENTITY_DESC\n",
    ")\n",
    "print(\"-- create entity --\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "response = client.put_event_type (\n",
    "    name           = EVENT_TYPE,\n",
    "    eventVariables = eventVariables,\n",
    "    labels         = eventLabels,\n",
    "    entityTypes    = [ENTITY_TYPE])\n",
    "print(\"-- create event type --\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create & Train your Model\n",
    "-----\n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Train Model. </strong>\n",
    "\n",
    "The following section will automatically train and activate your model for you. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- initalize model --\n",
      "{'ResponseMetadata': {'RequestId': '66aca5cd-0b28-4234-824f-d6a534f3341e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Dec 2020 02:34:20 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': '66aca5cd-0b28-4234-824f-d6a534f3341e'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the CreateModelVersion operation: The CSV header does not contain the necessary variables",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f9bb48bde64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     externalEventsDetail = {\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m'dataLocation'\u001b[0m     \u001b[0;34m:\u001b[0m \u001b[0mS3_FILE_LOC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;34m'dataAccessRoleArn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mARN_ROLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationException\u001b[0m: An error occurred (ValidationException) when calling the CreateModelVersion operation: The CSV header does not contain the necessary variables"
     ]
    }
   ],
   "source": [
    "# --- no changes; just run this code block. ---\n",
    "\n",
    "# -- create our model --\n",
    "response = client.create_model(\n",
    "   description   =  MODEL_DESC,\n",
    "   eventTypeName = EVENT_TYPE,\n",
    "   modelId       = MODEL_NAME,\n",
    "   modelType   = 'ONLINE_FRAUD_INSIGHTS')\n",
    "\n",
    "print(\"-- initalize model --\")\n",
    "print(response)\n",
    "# -- initializes the model, it's now ready to train -- \n",
    "response = client.create_model_version(\n",
    "    modelId     = MODEL_NAME,\n",
    "    modelType   = 'ONLINE_FRAUD_INSIGHTS',\n",
    "    trainingDataSource = 'EXTERNAL_EVENTS',\n",
    "    trainingDataSchema = trainingDataSchema,\n",
    "    externalEventsDetail = {\n",
    "        'dataLocation'     : S3_FILE_LOC,\n",
    "        'dataAccessRoleArn': ARN_ROLE\n",
    "    }\n",
    ")\n",
    "print(\"-- model training --\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "# -- model training takes time, we'll loop until it's complete  -- \n",
    "print(\"-- wait for model training to complete --\")\n",
    "stime = time.time()\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = client.get_model_version(modelId=MODEL_NAME, modelType = \"ONLINE_FRAUD_INSIGHTS\", modelVersionNumber = '1.0')\n",
    "    if response['status'] == 'TRAINING_IN_PROGRESS':\n",
    "        print(f\"current progress: {(time.time() - stime)/60:{3}.{3}} minutes\")\n",
    "        time.sleep(60)  # -- sleep for 60 seconds \n",
    "    if response['status'] != 'TRAINING_IN_PROGRESS':\n",
    "        print(\"Model status : \" +  response['status'])\n",
    "        break\n",
    "        \n",
    "etime = time.time()\n",
    "\n",
    "# -- summarize -- \n",
    "print(\"\\n --- model training complete  --\")\n",
    "print(\"Elapsed time : %s\" % (etime - stime) + \" seconds \\n\"  )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.update_model_version_status (\n",
    "    modelId = MODEL_NAME,\n",
    "    modelType = 'ONLINE_FRAUD_INSIGHTS',\n",
    "    modelVersionNumber = '1.0',\n",
    "    status = 'ACTIVE'\n",
    ")\n",
    "print(\"-- activating model --\")\n",
    "print(response)\n",
    "\n",
    "#-- wait until model is active \n",
    "print(\"--- waiting until model status is active \")\n",
    "stime = time.time()\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = client.get_model_version(modelId=MODEL_NAME, modelType = \"ONLINE_FRAUD_INSIGHTS\", modelVersionNumber = '1.0')\n",
    "    if response['status'] != 'ACTIVE':\n",
    "        print(f\"current progress: {(time.time() - stime)/60:{3}.{3}} minutes\")\n",
    "        time.sleep(60)  # sleep for 1 minute \n",
    "    if response['status'] == 'ACTIVE':\n",
    "        print(\"Model status : \" +  response['status'])\n",
    "        break\n",
    "        \n",
    "etime = time.time()\n",
    "print(\"Elapsed time : %s\" % (etime - stime) + \" seconds \\n\"  )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- model performance summary -- \n",
    "auc = client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingResult']['trainingMetrics']['auc']\n",
    "\n",
    "\n",
    "df_model = pd.DataFrame(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingResult']['trainingMetrics']['metricDataPoints'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(df_model[\"fpr\"], df_model[\"tpr\"], color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.3f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title( MODEL_NAME + ' ROC Chart')\n",
    "plt.legend(loc=\"lower right\",fontsize=12)\n",
    "plt.axvline(x = 0.02 ,linewidth=2, color='r')\n",
    "plt.axhline(y = 0.73 ,linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Detector, generate Rules and assemble your Detector\n",
    "\n",
    "-----\n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Generate Rules, Create and Publish a Detector. </strong>\n",
    "    \n",
    "The following section will automatically generate a number of fraud, investigate and approve rules based on the false positive rate and score thresholds of your model. These are just example rules that you could create, it is recommended that you fine tune your rules specifically to your business use case.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- initialize your detector -- \n",
    "response = client.put_detector(detectorId  = DETECTOR_NAME, \n",
    "                               description = DETECTOR_DESC, \n",
    "                               eventTypeName = EVENT_TYPE )\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- make rules -- \n",
    "model_stat = df_model.round(decimals=2)  \n",
    "\n",
    "m = model_stat.loc[model_stat.groupby([\"fpr\"])[\"threshold\"].idxmax()] \n",
    "\n",
    "def make_rule(x):\n",
    "    rule = \"\"\n",
    "    if x['fpr'] <= 0.05: \n",
    "        rule = \"${0}_insightscore > {1}\".format(MODEL_NAME,x['threshold'])\n",
    "    if x['fpr'] == 0.06:\n",
    "        rule = \"${0}_insightscore <= {1}\".format(MODEL_NAME,x['threshold_prev'])\n",
    "    return rule\n",
    "    \n",
    "m[\"threshold_prev\"] = m['threshold'].shift(1)\n",
    "m['rule'] = m.apply(lambda x: make_rule(x), axis=1)\n",
    "\n",
    "m['outcome'] = \"approve\"\n",
    "m.loc[m['fpr'] <= 0.03, \"outcome\"] = \"fraud\"\n",
    "m.loc[(m['fpr'] > 0.03) & (m['fpr'] <= 0.05), \"outcome\"] = \"investigate\"\n",
    "\n",
    "print (\" --- score thresholds 1% to 6% --- \")\n",
    "print(m[[\"fpr\", \"tpr\", \"threshold\", \"rule\", \"outcome\"]].loc[(m['fpr'] > 0.0 ) & (m['fpr'] <= 0.06)].reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- create outcomes -- \n",
    "def create_outcomes(outcomes):\n",
    "    \"\"\" create Fraud Detector Outcomes \n",
    "    \n",
    "    \"\"\"   \n",
    "    for outcome in outcomes:\n",
    "        print(\"creating outcome variable: {0} \".format(outcome))\n",
    "        response = client.put_outcome(\n",
    "                          name=outcome,\n",
    "                          description=outcome)\n",
    "\n",
    "# -- get distinct outcomes \n",
    "outcomes = m[\"outcome\"].unique().tolist()\n",
    "\n",
    "create_outcomes(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_set = m[(m[\"fpr\"] > 0.0) & (m[\"fpr\"] <= 0.06)][[\"outcome\", \"rule\"]].to_dict('records')\n",
    "rule_list = []\n",
    "for i, rule in enumerate(rule_set):\n",
    "    ruleId = \"rule{0}_{1}\".format(i, MODEL_NAME)\n",
    "    rule_list.append({\"ruleId\": ruleId, \n",
    "                      \"ruleVersion\" : '1',\n",
    "                      \"detectorId\"  : DETECTOR_NAME\n",
    "        \n",
    "    })\n",
    "    print(\"creating rule: {0}: IF {1} THEN {2}\".format(ruleId, rule[\"rule\"], rule['outcome']))\n",
    "    try:\n",
    "        response = client.create_rule(\n",
    "            ruleId = ruleId,\n",
    "            detectorId = DETECTOR_NAME,\n",
    "            expression = rule['rule'],\n",
    "            language = 'DETECTORPL',\n",
    "            outcomes = [rule['outcome']]\n",
    "            )\n",
    "    except:\n",
    "        print(\"this rule already exists in this detector\")\n",
    "rule_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_detector_version(\n",
    "    detectorId = DETECTOR_NAME,\n",
    "    rules = rule_list,\n",
    "    modelVersions = [{\"modelId\":MODEL_NAME, \n",
    "                      \"modelType\" : \"ONLINE_FRAUD_INSIGHTS\",\n",
    "                      \"modelVersionNumber\" : \"1.0\"}],\n",
    "    ruleExecutionMode = 'FIRST_MATCHED'\n",
    "    )\n",
    "\n",
    "print(\"\\n -- detector created -- \")\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.update_detector_version_status(\n",
    "    detectorId= DETECTOR_NAME,\n",
    "    detectorVersionId='1',\n",
    "    status='ACTIVE'\n",
    ")\n",
    "print(\"\\n -- detector activated -- \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make Predictions \n",
    "-----\n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Make Predictions. </strong>\n",
    "    \n",
    "The following section will apply your detector to the first 10 records in your training dataset. To apply your detector to more simply change the record_count, alternatively you can specify the full training data with the following: \n",
    "\n",
    "</div>\n",
    "\n",
    "```python\n",
    "\n",
    "record_count = df.shape()[0]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- this will apply your detector to the first 10 records of your trainig dataset. -- \n",
    "record_count = 10 \n",
    "predicted_dat = []\n",
    "pred_data = df[eventVariables].head(record_count).astype(str).to_dict(orient='records')\n",
    "for rec in pred_data:\n",
    "    eventId = uuid.uuid1()\n",
    "    pred = client.get_event_prediction(detectorId=DETECTOR_NAME, \n",
    "                                       detectorVersionId='1',\n",
    "                                       eventId = str(eventId),\n",
    "                                       eventTypeName = EVENT_TYPE,\n",
    "                                       eventTimestamp = timestampStr, \n",
    "                                       entities = [{'entityType': ENTITY_TYPE, 'entityId':str(eventId.int)}],\n",
    "                                       eventVariables=rec) \n",
    "    \n",
    "    rec[\"score\"]   = pred['modelScores'][0]['scores'][\"{0}_insightscore\".format(MODEL_NAME)]\n",
    "    rec[\"outcome\"] = pred['ruleResults'][0]['outcomes']\n",
    "    predicted_dat.append(rec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- review your predictons -- \n",
    "predictions = pd.DataFrame(predicted_dat)\n",
    "head(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally Write Predictions to File\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Write Predictions. </strong>\n",
    "\n",
    "- You can write your prediction dataset to a CSV or Excel to manually review predictions\n",
    "- Simply add a cell below and copy the code below\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# -- optionally write predictions to a CSV file -- \n",
    "predictions.to_csv(MODEL_NAME + \".csv\", index=False)\n",
    "# -- or to a XLS file \n",
    "predictions.to_excel(MODEL_NAME + \".xlsx\", index=False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
